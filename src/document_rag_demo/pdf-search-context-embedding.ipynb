{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Use Ollama based Llama model from local machine\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    persist_directory=\"../../data/chroma4/\",\n",
    "    collection_name=\"doc_search_demo\",\n",
    "    embedding_function=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def fetch_files(directory: str) -> list[str] :\n",
    "    file_paths = []\n",
    "\n",
    "    for folder, subs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            file_paths.append(os.path.abspath(os.path.join(folder, filename)))\n",
    "\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "def call_llm_model(prompt: str) :\n",
    "\n",
    "    # LLM \n",
    "    llm = OllamaLLM(\n",
    "        model=\"llama3.2\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_contextual_chunks(chunks : list[str], document: str) -> list[str]:\n",
    "\n",
    "    CONTEXTUAL_EMBEDDING_PROMPT = \"\"\"\n",
    "        Here is the chunk we want to situate within the whole document:\n",
    "        <chunk>\n",
    "        {chunk}\n",
    "        </chunk>\n",
    " \n",
    "        Here is the content of the whole document:\n",
    "        <document>\n",
    "        {document}\n",
    "        </document>\n",
    " \n",
    "        Please provide a short, succinct context to situate this chunk within the overall document to improve search retrieval. Respond only with the context.\n",
    "    \"\"\"\n",
    "\n",
    "    contexual_chunks = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        prompt=CONTEXTUAL_EMBEDDING_PROMPT.format(chunk=chunk, document=document)\n",
    "        context_chunk = call_llm_model(prompt)\n",
    "        contexual_chunks.append(f\"{chunk}\\n{context_chunk}\")\n",
    "\n",
    "    return contexual_chunks\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "def persist_chunks_as_embeddings(documents):\n",
    "\n",
    "    uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "    vector_store_from_client.add_documents(documents=documents, ids= uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def construct_documents(chunks : list[str], metadata):\n",
    "    chunked_docs = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        metadata[\"chunk\"] = i\n",
    "        doc = Document(page_content=chunk, metadata=metadata)\n",
    "        chunked_docs.append(doc)\n",
    "\n",
    "    return chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size for page 0 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 1 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 2 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 3 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 4 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 5 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 6 on document Petra - Wikipedia is 3\n",
      "Chunk size for page 7 on document Petra - Wikipedia is 5\n",
      "Chunk size for page 8 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 9 on document Petra - Wikipedia is 4\n",
      "Chunk size for page 10 on document Petra - Wikipedia is 5\n",
      "Chunk size for page 11 on document Petra - Wikipedia is 2\n",
      "Chunk size for page 12 on document Petra - Wikipedia is 9\n",
      "Chunk size for page 13 on document Petra - Wikipedia is 9\n",
      "Chunk size for page 14 on document Petra - Wikipedia is 7\n",
      "Chunk size for page 15 on document Petra - Wikipedia is 9\n",
      "Chunk size for page 16 on document Petra - Wikipedia is 10\n",
      "Chunk size for page 17 on document Petra - Wikipedia is 10\n",
      "Chunk size for page 18 on document Petra - Wikipedia is 10\n",
      "Chunk size for page 19 on document Petra - Wikipedia is 6\n",
      "Chunk size for page 20 on document Petra - Wikipedia is 1\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "files = fetch_files(\"../../data/pdf\")\n",
    "\n",
    "# for file in files[1]:\n",
    "loader = PyPDFLoader(\"../../data/pdf/Petra.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "for page in pages:\n",
    "    token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 260, chunk_overlap = 20)\n",
    "    chunks = token_splitter.split_text(page.page_content)\n",
    "\n",
    "    print(f\"Chunk size for page {page.metadata.get(\"page\")} on document {page.metadata.get(\"title\")} is {len(chunks)}\")\n",
    "    \n",
    "    contextual_chunks = create_contextual_chunks(chunks, page.page_content)\n",
    "    persist_chunks_as_embeddings(construct_documents(contextual_chunks, page.metadata))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who lived in the north of petra?',\n",
       " 'context': [Document(id='b45a0a2f-4553-4f05-8508-2441e65fb799', metadata={'chunk': 3, 'creationdate': '2025-03-27T12:32:03+00:00', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/128.0.0.0 Safari/537.36', 'moddate': '2025-03-27T12:32:03+00:00', 'page': 4, 'page_label': '5', 'producer': 'Skia/PDF m128', 'source': '../../data/pdf/Petra.pdf', 'title': 'Petra - Wikipedia', 'total_pages': 21}, page_content='be the Isis-Tyche, Isis and Tyche being the Egyptian and Greek goddesses, respectively, of good fortune.[49]\\n21st century\\nLayout\\nHellenistic architecture\\nThis chunk discusses the Hellenistic architecture and features of Petra, including its tombs, facades, and notable structures such as the Treasury, which reflect the cultural influences of Greek culture on the Nabataeans.'),\n",
       "  Document(id='4e06b6c4-ce69-4325-b6ac-f89cdc9502f1', metadata={'chunk': 3, 'creationdate': '2025-03-27T12:32:03+00:00', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/128.0.0.0 Safari/537.36', 'moddate': '2025-03-27T12:32:03+00:00', 'page': 4, 'page_label': '5', 'producer': 'Skia/PDF m128', 'source': '../../data/pdf/Petra.pdf', 'title': 'Petra - Wikipedia', 'total_pages': 21}, page_content=\"rock at the top. Near the bottom of the Treasury are the twin Greek gods Castor\\nand Pollux, who protect travellers on their journeys. Near the top of the\\nTreasury, two victories are seen standing on each side of a female figure on the tholos. This female figure is believed to\\nbe the Isis-Tyche, Isis and Tyche being the Egyptian and Greek goddesses, respectively, of good fortune.[49]\\n21st century\\nLayout\\nHellenistic architecture\\nThis section discusses the Hellenistic architecture and layout of Petra, including its unique features such as the Treasury building, and provides historical context on the Nabataeans' control of water supply and their cultural influences.\"),\n",
       "  Document(id='60fd9caf-8a13-4e8e-bdb0-ffa69845d22c', metadata={'chunk': 4, 'creationdate': '2025-03-27T12:32:03+00:00', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/128.0.0.0 Safari/537.36', 'moddate': '2025-03-27T12:32:03+00:00', 'page': 2, 'page_label': '3', 'producer': 'Skia/PDF m128', 'source': '../../data/pdf/Petra.pdf', 'title': 'Petra - Wikipedia', 'total_pages': 21}, page_content='sometime before 687 when that function had been transferred to Areopolis. Petra is not mentioned in the narratives of\\nRoman period\\nByzantine period\\nContext: This section describes the history of Petra under Roman rule, including its decline and eventual abandonment, from AD 106 to the Byzantine period (approximately 363-687).'),\n",
       "  Document(id='ba04caa9-b356-406d-80e6-683810d4527b', metadata={'chunk': 2, 'creationdate': '2025-03-27T12:32:03+00:00', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/128.0.0.0 Safari/537.36', 'moddate': '2025-03-27T12:32:03+00:00', 'page': 6, 'page_label': '7', 'producer': 'Skia/PDF m128', 'source': '../../data/pdf/Petra.pdf', 'title': 'Petra - Wikipedia', 'total_pages': 21}, page_content=\"Red Sea, and across the desert to the Persian Gulf.[24]\\nThe Nabataeans worshipped Arab gods and goddesses during\\nthe pre-Islamic era as well as a few of their deified kings.\\nOne, Obodas I, was deified after his death in 85 BC. Dushara\\nwas the primary male god accompanied by his three female\\ndeities: Al-‘Uzzā, Allat and Manāt. Many statues carved in\\nthe rock depict these gods and goddesses. New evidence\\nindicates that broader Edomite, and Nabataean theology had strong links to Earth-Sun relationships, often manifested\\nin the orientation of prominent Petra structures to equinox and solstice sunrises and sunsets.[63]\\nRoyal Tombs\\nExterior platform\\nReligious importance\\nThis section discusses the Royal Tombs of Petra, including their architecture, religious significance, and connections to Nabataean theology, as part of the broader overview of Petra's history and cultural importance.\")],\n",
       " 'answer': \"I don't know who specifically lived in the north of Petra. The text mentions that the Nabataeans worshipped Arab gods and goddesses, but it does not provide information on specific groups or individuals living in the northern part of Petra.\"}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm = OllamaLLM(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "retriever = vector_store_from_client.as_retriever()\n",
    "\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use four sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "chain.invoke({\"input\": \"Who lived in the north of petra?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
